{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mais processamento de dados com pandas.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPAeflH0XQRwuptVm718Pjq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"r9FcrDlLOsJA"},"source":["# Fundindo DataFrames (Merge)"]},{"cell_type":"markdown","metadata":{"id":"cE9tWT-NPP8K"},"source":["Nesta sessão vamos vamos aprender a juntar dataFrames, tanto horizontalmente como concatenando verticalmente. \n","\n","Para entender isso vamos conceituar o processo como algo semelhante a um diagrama de veins\n","\n","Diagramas de veins separam os valores em categorias, e permitindo enxergar valores que representam nenhum, uma ou mais categorias.\n","\n","\n","Quando trazemos isso ao pandas, podemos pensar que temos duas populações, com indices separados. Quando quisermos juntar esses dataframes, temos algumas escolhas a tomar.\n","\n","Para exemplificar. Vamos supor dataframes de alunos e de funcionários de alguma faculdade. Se quisermos uma lista de todos. Em linguagem de dados seria um *full outer join*. E na teoria de probabilidade seria uma união. (Todos os circulos do diagrama).\n","\n","É possível que queiramos apenas aqueles que são funcionários e estudantes. *Inner Join* (A intersecção do diagrama)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Js1xiq9GCT8w","executionInfo":{"status":"ok","timestamp":1620944106633,"user_tz":180,"elapsed":3645,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"40760290-f090-4724-d8f0-4bde36e8b6d4"},"source":["#Vamos ver como isso funciona com pandas na prática.\n","\n","import pandas as pd\n","\n","#Vamos criar dois dataframes\n","\n","staff = pd.DataFrame([{'Nome' : 'Kelly', 'Cargo' : 'Diretor'},\n","                      {'Nome' : 'Sally', 'Cargo' : 'Monitor'},\n","                      {'Nome' : 'James', 'Cargo' : 'Professor'}])\n","\n","staff = staff.set_index('Nome')\n","\n","student = pd.DataFrame([{'Nome' : 'James', 'Curso' : 'Empreendedorismo'},\n","                        {'Nome' : 'Mike' , 'Curso' : 'Direito'},\n","                        {'Nome' : 'Sally' , 'Curso' : 'Engenharia'}])\n","\n","student = student.set_index('Nome')\n","\n","print(student.head())\n","\n","print(staff.head())\n","\n","#Importante que o indice do dataframe seja aquilo que queiramos juntar\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["                  Curso\n","Nome                   \n","James  Empreendedorismo\n","Mike            Direito\n","Sally        Engenharia\n","           Cargo\n","Nome            \n","Kelly    Diretor\n","Sally    Monitor\n","James  Professor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ae79oYQLVA7U","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1620944106636,"user_tz":180,"elapsed":3622,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"933bcc0c-c0ad-4243-981f-b5472e45524f"},"source":["#Se quisermos a união destes dataFrames, chamamos o função 'merge()' passando os dois dataframes, e dizendo que queremos outerjoin. Queremos usar os indices\n","# da direita e da esquerda e juntar as colunas\n","\n","pd.merge(staff, student, how='outer', left_index=True, right_index=True)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","    <tr>\n","      <th>Nome</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>James</th>\n","      <td>Professor</td>\n","      <td>Empreendedorismo</td>\n","    </tr>\n","    <tr>\n","      <th>Kelly</th>\n","      <td>Diretor</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Mike</th>\n","      <td>NaN</td>\n","      <td>Direito</td>\n","    </tr>\n","    <tr>\n","      <th>Sally</th>\n","      <td>Monitor</td>\n","      <td>Engenharia</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Cargo             Curso\n","Nome                              \n","James  Professor  Empreendedorismo\n","Kelly    Diretor               NaN\n","Mike         NaN           Direito\n","Sally    Monitor        Engenharia"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"yMhD52JvxBZu","executionInfo":{"status":"ok","timestamp":1620944106637,"user_tz":180,"elapsed":3601,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"b771be48-b99d-4f47-fcd3-f001709dc5cb"},"source":["#A união dos dois dataframes retornou todos os valores nos dataframes. Se quisermos pegar uma intersecção, ou seja, apenas as pessoas que são estudantes e funcionaios\n","# Devemos usar o atributo 'inner'.\n","pd.merge(staff,student, how='inner', left_index = True, right_index = True)\n"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","    <tr>\n","      <th>Nome</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Sally</th>\n","      <td>Monitor</td>\n","      <td>Engenharia</td>\n","    </tr>\n","    <tr>\n","      <th>James</th>\n","      <td>Professor</td>\n","      <td>Empreendedorismo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Cargo             Curso\n","Nome                              \n","Sally    Monitor        Engenharia\n","James  Professor  Empreendedorismo"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"TEqCTF8TxBea","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1620944106638,"user_tz":180,"elapsed":3582,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"b6e17ffc-411d-4b0e-c021-5e497be7249e"},"source":["#Agora, dois outros casos interessantes, ambos que podem ser chamados de 'definir adição'.  Aprimeira é se quisermos uma lista de todos os funcionarios,\n","#independente se são estudantes ou não. Mas se eles forem, gostariamos de vizualizar os detalhes. Podemos fazer isso com um 'left join', é importante notar\n","#a ordem dos dataframes na função. o da esquerda é o da esquerda, o segunda da direita.\n","\n","pd.merge(staff, student, how='left', left_index=True, right_index=True)\n","\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","    <tr>\n","      <th>Nome</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Kelly</th>\n","      <td>Diretor</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Sally</th>\n","      <td>Monitor</td>\n","      <td>Engenharia</td>\n","    </tr>\n","    <tr>\n","      <th>James</th>\n","      <td>Professor</td>\n","      <td>Empreendedorismo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Cargo             Curso\n","Nome                              \n","Kelly    Diretor               NaN\n","Sally    Monitor        Engenharia\n","James  Professor  Empreendedorismo"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"IyLHk6Cy88el","executionInfo":{"status":"ok","timestamp":1620944106640,"user_tz":180,"elapsed":3566,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"78732fb4-6f6a-47d7-db36-ad05e8953531"},"source":["#Obviamente, podemos tentar fazer o inverso, vizualizar todos que são estudantes, e suas funções caso sejam funcionarios. \n","pd.merge(staff, student, how ='right', left_index=True, right_index=True)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","    <tr>\n","      <th>Nome</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>James</th>\n","      <td>Professor</td>\n","      <td>Empreendedorismo</td>\n","    </tr>\n","    <tr>\n","      <th>Mike</th>\n","      <td>NaN</td>\n","      <td>Direito</td>\n","    </tr>\n","    <tr>\n","      <th>Sally</th>\n","      <td>Monitor</td>\n","      <td>Engenharia</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Cargo             Curso\n","Nome                              \n","James  Professor  Empreendedorismo\n","Mike         NaN           Direito\n","Sally    Monitor        Engenharia"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"UHgLA0DZ-ClK","executionInfo":{"status":"ok","timestamp":1620944106641,"user_tz":180,"elapsed":3546,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"01ff8d1e-eba4-4025-fd8e-7bf996784644"},"source":["#Nós podemos fazer isso de outra forma também. O método merge tem alguns outros interessantes parametros. Primeiro, você não precisa usar indices\n","#Você também pode usar as colunas, por exemplo: Vamos usar o parametro chamado 'on', e podemos assimila-lo aos dataframes e juntando como colunas:\n","\n","#primeiro, vamos remover os indices dos dois dataframes:\n","staff = staff.reset_index()\n","student = student.reset_index()\n","\n","#Agora, vamos junta-los usanndo o parametro 'on':\n","pd.merge(staff, student, how='right', on='Nome')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Nome</th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>James</td>\n","      <td>Professor</td>\n","      <td>Empreendedorismo</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mike</td>\n","      <td>NaN</td>\n","      <td>Direito</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sally</td>\n","      <td>Monitor</td>\n","      <td>Engenharia</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Nome      Cargo             Curso\n","0  James  Professor  Empreendedorismo\n","1   Mike        NaN           Direito\n","2  Sally    Monitor        Engenharia"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"GHXBMuF1CapV","executionInfo":{"status":"ok","timestamp":1620944106642,"user_tz":180,"elapsed":3528,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"473268ee-8ac0-46d4-f04b-7d39e7799615"},"source":["#Então, o que acontece se tivermos conflitos entre os os DataFrames? Vamos dar uma olhada criando novos dataframes e adicionando o Local.\n","\n","staff = pd.DataFrame([{'Nome': 'Kelly', 'Cargo': 'Diretor de filme', 'Local' : 'Rua Estadual'},\n","                      {'Nome': 'Sally', 'Cargo': 'Monitor', 'Local': 'Avenida Washington'},\n","                      {'Nome': 'James', 'Cargo': 'Professor', 'Local': 'Avenida Washington'}])\n","\n","student = pd.DataFrame([{'Nome': 'James', 'Curso': 'Empreendedorismo', 'Local': '1024 Avenida Paulista'},\n","                        {'Nome' : 'Mike', 'Curso' : 'Direito', 'Local': 'Republica #22'},\n","                        {'Nome' : 'Sally', 'Curso' : 'Engenharia', 'Local': 'Faria Lima'}])\n","\n","#No dataframe dos funcionários, tem o local do escritório. No dataframe dos estudantes, o local representa sua residencia.\n","\n","#O método 'merge' mantem essa informação, mas acrescenta um _x/_y para ajudar a diferenciar de qual dataframe veio a informaçãp\n","# O _x é sempre o dataframe da esquerda e o _y da direita.\n","\n","#Agora se quisermos a informação de todos os funcionários independente se são estudantes ou não. Mas se forem, exibe os detalhes.\n","pd.merge(staff, student, how='left', on='Nome')"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Nome</th>\n","      <th>Cargo</th>\n","      <th>Local_x</th>\n","      <th>Curso</th>\n","      <th>Local_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kelly</td>\n","      <td>Diretor de filme</td>\n","      <td>Rua Estadual</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sally</td>\n","      <td>Monitor</td>\n","      <td>Avenida Washington</td>\n","      <td>Engenharia</td>\n","      <td>Faria Lima</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>James</td>\n","      <td>Professor</td>\n","      <td>Avenida Washington</td>\n","      <td>Empreendedorismo</td>\n","      <td>1024 Avenida Paulista</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Nome             Cargo  ...             Curso                Local_y\n","0  Kelly  Diretor de filme  ...               NaN                    NaN\n","1  Sally           Monitor  ...        Engenharia             Faria Lima\n","2  James         Professor  ...  Empreendedorismo  1024 Avenida Paulista\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"ADrI-FtmLDvZ","executionInfo":{"status":"ok","timestamp":1620944107475,"user_tz":180,"elapsed":4339,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"9fc7a44a-9652-499b-c8b7-5b706d41063f"},"source":[" #Como dito antes, e reiterado pela saida, podemos ver que existe a coluna, local_x e local_y, onde o x representa o local do staff dataframe (left),\n"," #e o y o dataframe dos estudantes(right).\n","\n"," #Antes de deixar o assunto da fusão de dataFrames (merging), Vamos falar sobre multi-indices e colunas.\n"," #Seria bem comum, que o nome de um funcionário e um estudante fossem os mesmos, mas não o sobrenome. Neste caso, usamos uma lista de multiplas colunas\n"," #que devem ser passadas como as chaves a serem juntadas ('Join keys'), de ambos os dataframes como parametro. Veja um exemplo:\n","\n","staff = pd.DataFrame([{'Nome' : 'Kelly', 'Sobrenome': 'Matos', 'Cargo' : 'Diretora'},\n","                      {'Nome' : 'Sally', 'Sobrenome' : 'Borges', 'Cargo' : 'Monitora'},\n","                      {'Nome' : 'James', 'Sobrenome' : 'Whinderson', 'Cargo'  : 'Professor'}])\n","\n","student = pd.DataFrame([{'Nome' : 'James', 'Sobrenome' : 'Havan', 'Curso' : 'Empreendedorismo'},\n","                        {'Nome' : 'Michel', 'Sobrenome' : 'Santos', 'Curso' : 'Direito'},\n","                        {'Nome' : 'Sally', 'Sobrenome' : 'Borges' , 'Curso' : 'Engenharia'}])\n","\n","#Como você ve aqui, Temos dois James diferentes, logo suas duas chaves não vão bater mutuamente. Então se fizermos um 'inner join' (intersecção),\n","#teremos apenas aqueles que são funcionarios e alunos.\n","pd.merge(staff, student, how='inner', on = ['Nome','Sobrenome'])\n","  \n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Nome</th>\n","      <th>Sobrenome</th>\n","      <th>Cargo</th>\n","      <th>Curso</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sally</td>\n","      <td>Borges</td>\n","      <td>Monitora</td>\n","      <td>Engenharia</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Nome Sobrenome     Cargo       Curso\n","0  Sally    Borges  Monitora  Engenharia"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"CNZBdfi5wvSP","executionInfo":{"status":"ok","timestamp":1620944107476,"user_tz":180,"elapsed":4336,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#juntar dataframes é uma tarefa bem comum e você precisa saber como selecionar os dados de diferentes fontes, limpa-los, então concatena-los\n","#(junta-los verticalmente) e enfim analisa-los.\n","\n","#Podemos pensar 'merging' como juntar horizontalmente valores similares em uma coluna encontrada em dois dataframes e concatenar como juntar verticalmnte\n","#Significando como colocassemos um dataframe no topo ou fim um do outro.\n","\n","#Vamos usar um exemplo, você tem um dataset que contem algumas informações através de alguns anos, e cada ano é um arquivo CSV de mesmo número de colunas\n","#O que acontece se quisermos puxar todos os dados, de todos os anos arquivados, juntos? Podemos concatena-los."],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXC3FZyE-FfH","executionInfo":{"status":"ok","timestamp":1620944107477,"user_tz":180,"elapsed":4333,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos dar uma olhada nos dados do 'US Departament of Education College Scorecard'. Ele contem cada universidade dos USA e dados gerais sobre seus alunos\n","#Os dados estão guardados em diferentes CSV's para diferentes anos. Vamos supor que queremos os arquivos entre 2011 e 2013 nós primeiro criamos três dataframes\n","#(um para cada ano),  e como os dados estão meio bagunçados, vamos se esquivar de alguns erros que provavelmente acontecerá no ambiente de execução. \n","#Para isso vamos usar um comando de celula magica chamda %%capture"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3k7n3PKAaqZ","executionInfo":{"status":"ok","timestamp":1620944107477,"user_tz":180,"elapsed":4329,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"c10e7163-e23c-4484-ea50-8ff4b19e2dd8","colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["%%capture\n","\n","df_2011 = pd.read_csv('MERGED2011_12_PP.csv', error_bad_lines=False)\n","df_2012 = pd.read_csv('MERGED2012_13_PP.csv', error_bad_lines=False)\n","df_2013 = pd.read_csv('MERGED2013_14_PP.csv', error_bad_lines=False)"],"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-3a6c3fb95b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_2011\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MERGED2011_12_PP.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_2012\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MERGED2012_13_PP.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MERGED2013_14_PP.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MERGED2011_12_PP.csv'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"-sMPPZR3w5x5","executionInfo":{"status":"error","timestamp":1620944107931,"user_tz":180,"elapsed":4763,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}},"outputId":"8914d6e0-332f-4158-9925-225ea17207b0"},"source":["#Vamos dar uma olhada:\n","df_2011.head(5)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-81623a7c9dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Vamos dar uma olhada:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_2011\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_2011' is not defined"]}]},{"cell_type":"code","metadata":{"id":"mB8624qexX3a","executionInfo":{"status":"aborted","timestamp":1620944107478,"user_tz":180,"elapsed":4291,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vemos que temos mais de 2000 colunas, vamos ver o tamanho de cada dataframe\n","print(len(df_2011))\n","print(len(df_2012))\n","print(len(df_2013))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E43hpWnLxvbS","executionInfo":{"status":"aborted","timestamp":1620944107479,"user_tz":180,"elapsed":4273,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos colocar todos os dataframes em uma lista a cja,a essa lista na função 'concat()'\n","\n","frames = [df_2011, df_2012, df_2013]\n","pd.concat(frames)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY0Nw8SNyYjw","executionInfo":{"status":"aborted","timestamp":1620944107480,"user_tz":180,"elapsed":4256,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["len(df_2011) + len(df_2012) + len(df_2013)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9tsvb-3yjdq","executionInfo":{"status":"aborted","timestamp":1620944107481,"user_tz":180,"elapsed":4239,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vemos que a quantidade de dados do dataframe gerado pela concatenação é identica a soma dos 3 dataframes. Mas agora\n","#temos um problema pois não sabemos de qual ano(dataframe) corresponde cada dado.\n","\n","#Podemos resolver com um parametro da função 'concat()', que o parametro 'keys' onde podemos colocar um nivel extra\n","#de indices. Nós passamos uma lista de chaves que queremos corresponder cada dataframe, veja:\n","\n","pd.concat(frames, keys=['2011','2012','2013'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SVNi3geztZI","executionInfo":{"status":"aborted","timestamp":1620944107482,"user_tz":180,"elapsed":4237,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora temos um multi indice de cada ano. A concatenação também possui um inner e outer method. Se estivermos concatenando \n","#dois dataframes que não possui colunas identicas, e escolher um método 'outer', algumas celulas vão ser NaN. Se escolher\n","#um método 'inner' então algumas informações NaN vão ser removidas. Você pode pensar nisso analogamente ao 'left'/'right'\n","#join, da função 'merge()'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36Nq2ygZ17jj"},"source":["#Pandas Idiomaticas\n"]},{"cell_type":"markdown","metadata":{"id":"A3kWe_og2FEG"},"source":["É comum, assim como na matemática, que digam que existem mais de uma solução para um problema. Ou na computação, várias maneiras de escrever um código que faz a mesma coisa. Mas algumas maneiras, ou soluções são mais apropriadas que outras. As melhores soluções são tomadas como Idiomáticas e geralmente são as mais usadas em exemplos, na internet/StackOverFlow.\n","\n","Um conjunto de sub-linguagem dentro do python, no caso Pandas, tem seus próprio conjunto idiomático. Vamos ver alguns agora, como vetorizar sempre que possivel, e não uar laços(loopings) se não precisar. Os desenvolvedores e usuários usam o termo **Pandorable**. Vamos lá:"]},{"cell_type":"code","metadata":{"id":"CwcffHLV2CCO","executionInfo":{"status":"aborted","timestamp":1620944107482,"user_tz":180,"elapsed":4233,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["import pandas as pd\n","import numpy as np\n","import timeit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1PmSCV24qD_","executionInfo":{"status":"aborted","timestamp":1620944107483,"user_tz":180,"elapsed":4216,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#E vamos novamente usar o dataset do census.\n","df = pd.read_csv('census.csv')\n","df1 = pd.read_csv('census.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCOc9uLh5JZ7","executionInfo":{"status":"aborted","timestamp":1620944107484,"user_tz":180,"elapsed":4198,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#De primeira, vamos falar do método encadeamento 'chaining'. A ideia geral é que todo método do objeto retorne a referencia deste objeto.\n","# A beleza disso é condensar diversas operações no dataframe, em apenas uma linha ou apenas um argumento.\n","\n","#vamos ver yma forma pandoravel de encadeamento:\n","\n","(df.where(df['SUMLEV'] ==50)\n","    .dropna()\n","    .set_index(['STNAME','CTYNAME'])\n","    .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBCLigd5RRsF","executionInfo":{"status":"aborted","timestamp":1620944107486,"user_tz":180,"elapsed":4197,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Primeiramente, vamos usar a função 'where()' no dataframe e passa-lo em uma mascara booleana que é apenas True para \n","#as linhas onde SUMLEV é igual a 50. Isso indica na fonte do nosso dados foi resumido ao nível dos condados. Com\n","#o resultado do 'where()' avaliado, nós removeremos (drop()) os valores em branco. Apenas lembrando que o where não\n","#remove os valores nulos por padrão. Então colocamos um indice no dataframe que queriamos no resultado e por fim \n","#renomeamos uma coluna. Quero que perceba, que ao invés de escrever o comando várias vezes, ou em apenas uma linha,\n","#como poderia ser feito, iniciamos com um paretensis para dizer ao python \"Eu vou spammar esse comando em diversas linhas\n","#para tornar mais legivel.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BT4-z15_mNqa","executionInfo":{"status":"aborted","timestamp":1620944107487,"user_tz":180,"elapsed":4179,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos ver um exemplo de uma maneira não 'pandoravel' de escrever isso. Lembrando que não tem nada de errado com esse\n","#código no sentido funcional. Pode até ser mais compreensivel, apenas não é uma maneira 'pandoravel' de escreve-lo.\n","\n","#Primeiro criamos um novo dataframe do original e chamamos de df1\n","df = df1[df1['SUMLEV'] == 50] #Desta forma, os NaNs já são dropados automaticamente\n","#Atualizamos o dataframe para haver novos indices, usaremos inplace = True, para realizar a operação no data frame mesmo\n","df.set_index(['STNAME','CTYNAME'], inplace= True)\n","#Vamos alterar o nome da coluna agora.\n","df.rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlmwSdfPnf7A","executionInfo":{"status":"aborted","timestamp":1620944107488,"user_tz":180,"elapsed":4162,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#A chave idiomática do python é entender quando isso não te ajuda, para isso, vamos criar uma função e verificar qual\n","#método é mais rapido.\n","#Para isso vamos criar funções e ver o seu tempo de execução, então:\n","\n","def first_approach():\n","  global df\n","  return (df.where(df['SUMLEV'] ==50)\n","          .dropna()\n","          .set_index(['STNAME','CTYNAME'])\n","          .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n","  \n","df = pd.read_csv('census.csv')\n","timeit.timeit(first_approach, number = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qEB7VYW6r_K","executionInfo":{"status":"aborted","timestamp":1620944107488,"user_tz":180,"elapsed":4146,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#agora testando a segunda abordagem, como pode ter percebido. Nós usamos uma variavel global na primeira abordagem\n","#Contudo, alterar uma variavel global dentro de uma função, modificará mesmo no escopo global, e não queremos isso no momento\n","#então, então na hora de aplicar a mascara escolhendo os valores 'SUMLEV' == 50, vamos criar um novo dataframe, então:\n","\n","def second_approach():\n","  global df\n","  new_df = df.where(df['SUMLEV'] == 50)\n","  new_df.set_index(['STNAME', 'CTYNAME'])\n","  new_df.rename(columns={'ESTIMATESBASE2010' : 'Estimates Base 2010'})\n","  return new_df\n","\n","df = pd.read_csv('census.csv')\n","timeit.timeit(second_approach, number = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxAjyRyzBjX8","executionInfo":{"status":"aborted","timestamp":1620944107489,"user_tz":180,"elapsed":4143,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Como acabamos de ver, o segundo método é mais rápido, e esse é um classico exemplo de legibilidade vs tempo\n","#Você verá muitos exemplos de encadeamentos pelos forums de computação e é importante que você consiga entender, mas tenha\n","#em mente que trás alguns problemas de performance essa idiomática."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EL87FAoxFef3","executionInfo":{"status":"aborted","timestamp":1620944107490,"user_tz":180,"elapsed":4142,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Outra função idiomática do panda. O python possui a incrivel função map. Que é uma espécie de base para programação funcional\n","#Quando usamos map no python, você passa uma função que queremos aplicar, e um iteravel, como uma lista, da qual queremos\n","#que a função seja aplicada. O resultado é que o a função é aplicada para cada item, e retorna uma lista com todos os resultados.\n","\n","#Pandas possui uma função semelhante chamada 'applymap'. Nesta função, você fornece uma função que quer operar em cada célula\n","#do dataframe, mas é pouco usado. Ao invés, nos vemos querendo aplicar a função através de cada linha do dataframe.\n","#E o pandas tem uma função para isso chamada 'apply',vamos ver um exemplo:\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwsczZvVQwZi","executionInfo":{"status":"aborted","timestamp":1620944107491,"user_tz":180,"elapsed":4141,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Ainda usando o census dataframe, temos 5 colunas que são relacionadas a estimativa populacional do ano. É bem razoavel querer\n","#criar novas colunas para os valores maximos e minimos, da para fazer isso de maneira fácil usando apply  e as funções\n","#de maximos e minimos do numpy.\n","\n","#Primeiro precisamos escrever uma função que pega uma linha de interesse, encontre os valores de max e min e retorne uma nova\n","#linha de dados. Nós podemos criar alguns pequenos slices de uma linha por projetar as colunas da população.\n","\n","#Então usamos as funções do numpy de max e min, e então criar uma nova série com o rotulo dos valores que representem os novos\n","#valores que queremos aplicar. \n","\n","def min_max(row):\n","  data = row[['POPESTIMATE2010',\n","              'POPESTIMATE2011',\n","              'POPESTIMATE2012',\n","              'POPESTIMATE2013',\n","              'POPESTIMATE2014',\n","              'POPESTIMATE2015']]\n","  return pd.Series({'min': np.min(data), 'max' : np.max(data)})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNpFQf6jV7kQ","executionInfo":{"status":"aborted","timestamp":1620944107492,"user_tz":180,"elapsed":4125,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Então, apenas precisamos chamar o apply no dataframe\n","\n","#apply pega a função e o eixo que queremos aplicar os parametros. Agora, nós temos que ser cuidadosos. Nós temos falado \n","#Sobre o eixo 0 ser as linhas do dataframe. Mas neste parametro, é realmente o parametro do indice a usar. Então, para usar\n","#Apply por todas as linhas, aplicando em todas as colunas, você passar o eixo sendo igual as colunas.\n","\n","df.apply(min_max, axis= 'columns').head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oo-XRRJZCXb","executionInfo":{"status":"aborted","timestamp":1620944107493,"user_tz":180,"elapsed":4122,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Claro que não precisamos nos limitar a criar um novo objeto (dataframe), se estivermos fazendo uma limpeza nos dados,\n","#poderemos querer adicionar esses novos dados ao dataframe, neste caso, apenas pega os valores das linhas e adiciona a uma\n","#nova coluna que indicam max e min. Isso faz parte do trabalho regular de trazer os dados e construir um resumo descritivo \n","#da estatistica. Isso é muito usado quando fundindo dataFrames. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KKuZBSfaw8L","executionInfo":{"status":"aborted","timestamp":1620944107493,"user_tz":180,"elapsed":4105,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos criar um exemplo revisando a nossa função de max e min anterior. Ao invés de retornar uma série separada, vamos criar\n","#novas colunas no dataframe para armazenar esses dados. \n","\n","def min_max(row):\n","  data = row[['POPESTIMATE2010',\n","              'POPESTIMATE2011',\n","              'POPESTIMATE2012',\n","              'POPESTIMATE2013',\n","              'POPESTIMATE2014',\n","              'POPESTIMATE2015']]\n","  row['max'] = np.max(data)\n","  row['min'] = np.min(data)\n","  return row\n","\n","#Agora apenas usamos apply através do dataframe.\n","\n","df.apply(min_max, axis='columns')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CcqJCgwacfSn","executionInfo":{"status":"aborted","timestamp":1620944107494,"user_tz":180,"elapsed":4088,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Apply é uma funçao bem util de nosso arsenal. A razão pelo qual foi introduzido é porque raramente vemos ela sendo usada \n","# Com funções de larga definição. Como fizemos. Ao invés, vemos tipicamente isso sendo usado com lambdas.\n","\n","# Aqui, podemos imaginar como encadear várias chamadas de apply com uma função lambda juntos para criar uma legivel e sucinta\n","# Manipulação, veremosum exemplo de usar lambda e apply para encontrar os max e min.\n","\n","rows = ['POPESTIMATE2010','POPESTIMATE2011','POPESTIMATE2012','POPESTIMATE2013', 'POPESTIMATE2014','POPESTIMATE2015']\n","\n","#Agora aplicaremos isso através dataframe com a função lambda.\n","\n","df.apply(lambda x: np.max(x[rows]), axis= 1).head() # axis = 1 é sinomino de axis = columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbAU4u6LdmA6","executionInfo":{"status":"aborted","timestamp":1620944107495,"user_tz":180,"elapsed":4086,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Caso não lembre o que é uma função lambda. Uma função lambda é apenas uma função sem nome que pega parametros e retornam\n","#apenas um valor, neste caso, o maximo através de todas as colunas associadas as linhas 'x'.\n","\n","#A beleza do apply é que nos da uma maior flexibilidade em fazer a manipulação que quisermos. Como a função que passamos pode\n","#ser customizada. Vamos supor que queremos separar os estados em categorias: Centroeste, nordeste, sul e oeste.\n","\n","def get_state(x):\n","  northeast = ['Connecticut', 'Maine','Massachusetts','New Hampshire','Rhode Island','Vermont','New York','New Jersey','Pennsylvania']\n","  midwest = ['Illinois','Indiana','Michigan','Ohio','Wisconsin','Iowa','Kansas','Minnesota','Missouri','Nebraska','North Dakota','South Dakota']\n","  south = ['Delaware','Florida','Georgia','Maryland','North Carolina','South Carolina','Virginia','District of Columbia','West Virginia',\n","           'Alabama','Kentucky','Mississipi','Tennessee','Arkansas','Lousiana','Oklahoma','Texas']\n","  west = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah','Wyoming','Alaska','California','Hawaii','Oregon','Washington']\n","\n","  if x in northeast:\n","    return 'Northeast'\n","  elif x in midwest:\n","    return 'Midwest'\n","  elif x in south:\n","    return 'South'\n","  elif x in west:\n","    return 'West'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvz_b2yFIwVL","executionInfo":{"status":"aborted","timestamp":1620944107495,"user_tz":180,"elapsed":4070,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora que customizada a função, vamos criar uma nova coluna chamada 'região'. Que mostrará a região de um estado. Podemos usar\n","# a função, o comando 'apply' para isso. \n","\n","df['região'] = df['STNAME'].apply(lambda x: get_state(x))\n","df[['STNAME','região']].tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RKN25bfchu6"},"source":["#Agrupar"]},{"cell_type":"markdown","metadata":{"id":"BUl1D4Ftc5vR"},"source":["As vezes queremos selecionar os dados com base em grupos e compreender os dados agrupados categóricamente. Vimos que o pandas nos permite iterar sobre todas as linhas de um dataframe. Isso é genericament um processo muito lento. Felizmente, Pandas possui uma função 'groupby()' para acelerar tal tarefa. A idéia por trás dessa função é que ela pega um dataframe, divide em pedaços baseado em alguns valores chaves, e aplica a computação sobre esses valores. E então junta novamente os pedaços resultantes em um novo dataframe. Em pandas isso e chamado como 'Dividir - Aplicar - Combinar' padrões."]},{"cell_type":"markdown","metadata":{"id":"G5kCzFS_e_gd"},"source":["##Splitting (Dividindo)\n"]},{"cell_type":"code","metadata":{"id":"t3FXwgWBe_JW","executionInfo":{"status":"aborted","timestamp":1620944107496,"user_tz":180,"elapsed":4067,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCqOvwviJunU","executionInfo":{"status":"aborted","timestamp":1620944107497,"user_tz":180,"elapsed":4051,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos usar novamente o census.csv, então\n","\n","df = pd.read_csv('census.csv')\n","#E vamos excluir o 'State level summarizations, que contem sum level de 40\n","df[df['SUMLEV'] == 50]\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UM4FwP0hf_f","executionInfo":{"status":"aborted","timestamp":1620944107498,"user_tz":180,"elapsed":4049,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#No primeiro exemplo, vamos pegar uma lista contendo todos os estados, então vamos iterar pelos estados e para cada estado\n","#vamos reduzir o dataframe e calcular e media .\n","\n","#Vamos fazer essa tarefa 3 vezes e marcar o tempo, para isso, vamos usar a celula mágica com a função %%timeit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDLBMLUgi4il","executionInfo":{"status":"aborted","timestamp":1620944107499,"user_tz":180,"elapsed":4033,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["%%timeit -n 3\n","\n","for state in df['STNAME'].unique():\n","  #Vamos calcular a média usando numpy\n","  avg = np.average(df.where(df['STNAME'] == state).dropna()['CENSUS2010POP'])\n","  # E vamos imprimir isso na tela\n","\n","  print('Counties in state ' + state + 'have an average population of ' + str(avg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MQ-N2v_jX9y","executionInfo":{"status":"aborted","timestamp":1620944107500,"user_tz":180,"elapsed":4018,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos ver novamente, agora com outro método. Vamos começar por dizer ao pandas que estamos interessados em agrupar pelo \n","#nome do estado, isso é o 'split'.\n","\n","%%timeit -n 3\n","\n","for group, frame in df.groupby('STNAME'):\n","  #Você deve ter percebido que colocamos duas variaveis na iteração. Isso porque a função groupby() retorna uma tupla, onde\n","  #o primeiro valor é a chave, que nesse caso, é o nome do estado, e o segundo é projeção do dataframe encontrado para esse grupo\n","\n","  #Agora incluiremos a lógica do 'apply', que irá calcular a média, então:\n","  avg = np.average(frame['CENSUS2010POP'])\n","  # E imprimir os resultados:\n","  print('Counties in state ' + group + ' have an average population of ' +str(avg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysGv1RQUo-NM","executionInfo":{"status":"aborted","timestamp":1620944107501,"user_tz":180,"elapsed":4002,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Como podemos concluir, existe uma grande diferença na velocidade.\n","\n","#Em 99% do tempo, você irá usar 'groupby()' em uma ou mais colunas. Mas você também pode criar uma função para agrupar\n","#e usa-la para segmentar seus dados.\n","\n","#ISso é um exemplo fabricado,mas vamos dizer que temos um montante de trabalho, com muita coisa para processar, e você\n","#quer trabalhar em terços de estados ao mesmo tempo. Nós poderiamos criar alguma função que retorna um número entre zero e dois\n","#Baseado na inicial de cada estado. Então podemos usar o 'groupby()' para usar essa função e dividir o dataframe. É importante\n","#perceber que para realizar isso devemos colocar a coluna que queremos agrupar como indice do nosso dataframe.\n","\n","df = df.set_index('STNAME')\n","\n","def batch(item):\n","  if item[0] < 'M':\n","    return 0\n","  if item[0] < 'Q':\n","    return 1\n","  return 2\n","\n","#O dataframe deve ser agrupado de acordo com o numero do lote (batch), E vamos iterar por cara grupo de lote\n","for group, frame in df.groupby(batch):\n","  print('There are ' + str(len(frame)) + ' records in group ' + str(group) + ' for processing.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bYsOff_y9WB","executionInfo":{"status":"aborted","timestamp":1620944107501,"user_tz":180,"elapsed":4000,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Repare que desta vez não passamos o nome de uma coluna para agrupar. Como alternativa, Colocamos o index do dataframe para\n","#ser STNAME, e se nenhuma coluna for passada no identificador do 'groupby()', a função irá automaticamente usar o index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f345bXw5KMLw","executionInfo":{"status":"aborted","timestamp":1620944107502,"user_tz":180,"elapsed":3984,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos olhar mais um exemplo de como podemos agrupar dados. Desta vez, vamos usar o dataset fornecido pelo airbnb.\n","#Neste dataset temos duas colunas de interesse, 'cancellation_policy' e 'review_scores_value.\n","df = pd.read_csv('listings.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wbos-b7vNrgd","executionInfo":{"status":"aborted","timestamp":1620944107503,"user_tz":180,"elapsed":3972,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Então, como podemos agrupar os dados com base em duas colunas? Uma primeira abordagem, seria promover o dataframe\n","#em um nivel multi indices, e então apenas chamar a função 'groupby()'\n","df = df.set_index(['cancellation_policy','review_scores_value'])\n"," \n"," #Quando temos um multi indice nós precisamos passar em levels (ou camadas de indice) que estamos interessados em agrupar\n","for group, frame in df.groupby(level = (0)):\n","   print(group)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUjSx-dtUPXO","executionInfo":{"status":"aborted","timestamp":1620944107504,"user_tz":180,"elapsed":3961,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Isso parece funcionar. Mas se quisermos agrupar pelas politicas de cancelamento e revisão das notas, mas separando todos\n","#com nota dez dos que possuem nota inferior a 10. Neste caso, podemos usar uma função para gerir os agrupamentos.\n","\n","def grouping_fun(item):\n","  #Observe que os indices devem estar organizados em primeiro nivel a \"cancellation policy\" e o segundo nivel\n","  #score_review_value\n","\n","  if item[1] == 10:\n","    return(item[0], '10.0')\n","  else:\n","    return(item[0], 'not 10.0')\n","\n","for group, frame in df.groupby(by = grouping_fun):\n","  print(group)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttV83hStXSJI","executionInfo":{"status":"aborted","timestamp":1620944107505,"user_tz":180,"elapsed":3950,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9k4-pKjXiB3","executionInfo":{"status":"aborted","timestamp":1620944107506,"user_tz":180,"elapsed":3948,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Até este ponto, aplicamos simples processamentos nos nossos dados,após separa-lo, apenas verificando saídas para demonstrar\n","#como o 'splitting' funciona. Os desenvolvedores do pandas tem tres largas categorias de processamento de dados, para acontecer\n","#durante o passo de 'apply()'. Agregação dos grupos de dados, Transformação dos grupos de dados e a Filtragem dos grupos de dados."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4P4bEhSh3xM"},"source":["##Aggregation (Agregamento)\n"]},{"cell_type":"code","metadata":{"id":"Rp126xIxh20B","executionInfo":{"status":"aborted","timestamp":1620944107507,"user_tz":180,"elapsed":3936,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#O passa mais direto do apply é o agregamento de dados, e usa o método 'agg()' no objeto 'groupby()'. Até agora, nós apenas \n","#iteramos pelo os objetos dos agrupamentos, desempacotando em rotulos (nomes dos grupos) e o dataframe. Mas com 'agg()' podemos\n","#passar um dicionário de colunas que nós estamos interessados em agregar juntamente com a função que estamos buscando 'apply'\n","#a agregação.\n","import pandas as pd\n","import numpy as np\n","df = pd.read_csv('listings.csv')\n","\n","#Agora, vamos usar 'cancellation policys' e encontrar a média das notas de avaiação:\n","\n","df.groupby('cancellation_policy').agg({'review_scores_value' : np.average})\n","#Nas versões mais recentes do pandas, .agg() em um groupby objeto foi descontinuado, isso significa\n","#que devemos passar em funções customizadas para obter o efeito similar."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idN1KZYMm5bQ","executionInfo":{"status":"aborted","timestamp":1620944107508,"user_tz":180,"elapsed":3923,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Bem, isso não funcionou muito bem. Apenas um monte de valores (Not a Number NaN). O problema está na função,\n","#Que mandamos a ser agregada, np.average não ignora os valores NaN, Contudo tem uma função que podemos usar.\n","df.groupby('cancellation_policy').agg({'review_scores_value': np.nanmean})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jk7z2qCTo9n7","executionInfo":{"status":"aborted","timestamp":1620944107509,"user_tz":180,"elapsed":3907,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Nós podemos extender esse dicionario para agregar multiplas funções ou multiplas colunas.\n","df.groupby('cancellation_policy').agg({'review_scores_value' : (np.nanmean,np.nanstd),\n","                                       'reviews_per_month' : np.nanmean})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87MDKxeZqSjQ","executionInfo":{"status":"aborted","timestamp":1620944107510,"user_tz":180,"elapsed":3904,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos tomar um momento para ter certeza que entendeu a ultima celula, desde que isso é bem complexo. Primeiro, estamos\n","#fazendo um agrupamento do dataframe com base na coluna da politica de cancelamento. Isso cria um objeto 'groupby()'.\n","#Então invocamos a função 'agg()' neste objeto. A função agg vai aplicar uma ou mais funções que especificarmos ao grupo de dataframes\n","#e retorna uma unica linha por grupo/dataframe. Quando nós chamamos essa função, enviamos duas entradas e dicionários\n","#Cada uma indicando nas chaves, quais colunas queremos aplicar, e então a função a ser aplicada. Na primeira chave, passamos\n","# uma tupla, com duas funções. Perceba que cada função retornou em cada linha um valor. Perceba que não chamamos as funções,\n","#como estamos acostumados, com parenteses. "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TA1293UvKNC"},"source":["##Transformação (Transformation)"]},{"cell_type":"code","metadata":{"id":"MRVMRjbIvI_4","executionInfo":{"status":"aborted","timestamp":1620944107511,"user_tz":180,"elapsed":3900,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Transforamação é diferente de agragação , enquanto agg() retorna uma linha de valor para cada grupo, a transformação retorna\n","#um objeto que possui o mesmo tamanho do grupo. Essencialmente, isso reproduzirá a função por todo o grupo e retornará \n","#um novo dataframe.Isso faz a combinação de dados mais fácil."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBQ4VbPIclTs","executionInfo":{"status":"aborted","timestamp":1620944107512,"user_tz":180,"elapsed":3897,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["import numpy as np\n","import pandas as pd\n","df = pd.read_csv('listings.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwXMwfpsaE_6","executionInfo":{"status":"aborted","timestamp":1620944107513,"user_tz":180,"elapsed":3879,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Por exemplo, suponha que queremos incluir os valores da média de um dado grupo, em base na 'cancellation policy' mas preservando o formato\n","#do dataframe, então, o que poderiamos gerar a diferença uma observação individual e a soma.\n","\n","#Primeiro, vamos selecionar as colunas que nos interessa.\n","cols = ['cancellation_policy','review_scores_value']\n","#Agora, vamos transforma-lo.\n","\n","transform_df = df[cols].groupby('cancellation_policy').transform(np.nanmean)\n","transform_df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbwAbb7_ci-J","executionInfo":{"status":"aborted","timestamp":1620944107514,"user_tz":180,"elapsed":3857,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Então podemos ver que o indice aqui é atualmente o mesmo do dataframe original. Então vamos uni-lo ao dataframe. Antes\n","#disso, vamos renomear a coluna que não se trata mais dos valores das avaliações.\n","transform_df.rename({'review_scores_value':'review_scores_mean'}, axis= 1, inplace= True)\n","df = df.merge(transform_df, left_index= True, right_index=True)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tHyj75vhZA5","executionInfo":{"status":"aborted","timestamp":1620944107515,"user_tz":180,"elapsed":3808,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["df['review_scores_mean']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnPWNLTtfEcy","executionInfo":{"status":"aborted","timestamp":1620944107516,"user_tz":180,"elapsed":3779,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora podemos criar a diferença de uma dada linha, com o valor da média do grupo.\n","df['mean_diff'] = np.absolute(df['review_scores_value']-df['review_scores_mean'])\n","df['mean_diff'].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6x61sDtAjTOi"},"source":["##Filtrando (Filtering)"]},{"cell_type":"code","metadata":{"id":"vHlngdsSg3U_","executionInfo":{"status":"aborted","timestamp":1620944107517,"user_tz":180,"elapsed":3777,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Um objeto resultado da função 'groupby()' (agrupamento), tem suporte para filtrar grupos. Isso é interessante quando\n","# queremos agrupar por alguma caracteristica, e então fazer algumas transformações aos grupos e remover alguns grupos \n","#quando estamos limpando os dados. A função 'filter()' pega em uma função que é aplicada a cada grupo e então retorna\n","#Um valor booleano, e dependendo do resultado, o grupo é incluido nos resultados ou não."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I6vyx2wyjycJ","executionInfo":{"status":"aborted","timestamp":1620944107518,"user_tz":180,"elapsed":3761,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Por exemplo, se quisermos apenas os grupos que possuem uma média maior acima de 9 incluidas em nosso resultado\n","df.groupby('cancellation_policy').filter(lambda x: np.nanmean(x['review_scores_value']) > 9.2 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pMNnkgXkZq4","executionInfo":{"status":"aborted","timestamp":1620944107519,"user_tz":180,"elapsed":3757,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Note que os resutados continuam indexados, mas os valores do grupo com média abaixo de 9.2 não foram copiadas."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kpaov9muk9_K"},"source":["## Aplicando (Applying)"]},{"cell_type":"code","metadata":{"id":"oEXZCP19k9DQ","executionInfo":{"status":"aborted","timestamp":1620944107520,"user_tz":180,"elapsed":3738,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Essa é de longe a operação mais comum invocada quando está se agrupando é a função 'apply()'. Ela nos permite, \n","#aplicar uma função arbitrária para cada grupo, e costurar os resultados de volta para cada 'apply()' em um unico dataframe\n","#onde os indices se mantem preservados.\n","\n","#Vamos ver um exemplo, ainda nos mesmos dados.\n","\n","df = pd.read_csv('listings.csv')\n","# Vamos selecionar as colunas que nos interessam.\n","\n","df = df[['cancellation_policy','review_scores_value']]\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0EJP2fkmvJA","executionInfo":{"status":"aborted","timestamp":1620944107521,"user_tz":180,"elapsed":3720,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#No exemplo anterior, procuramos encontrar a média das avaliações de cada grupo e então calculamos os desvios padrôes de\n","#cada grupo. Isso foi um processo de dois passos, primeiro transformamos o objeto do 'groupby', e então transmitimos para \n","#criar uma nova coluna. COM 'apply()', nós podemos reduzir essa lógica.\n","\n","def calc_mean(group):\n","  #O grupo é um dataframe seja lá o parametro do nosso agrupamento, no nosso caso, é a 'cancellation policy', podemos trata-lo\n","  #como um dataframe completo.\n","\n","  avg = np.mean(group['review_scores_value'])\n","  #Agora transmitiremos a formula para criar uma nova coluna.\n","  group['review_scores_mean'] = np.abs(avg - group['review_scores_value'])\n","  return group\n","\n","#Agora apenas aplicaremos isto aos grupos\n","df.groupby('cancellation_policy').apply(calc_mean).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHq-H63wpd8b","executionInfo":{"status":"aborted","timestamp":1620944107522,"user_tz":180,"elapsed":3716,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["# Usar apply pode ser mais lento do que usar algumas funções especializadas, especialmente o 'agg()', Mas se o dataframe não é\n","# gigante, isso é uma firme abordagem geral."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lpXO-4iUqH0i"},"source":["#Scales (Escala?, Escamas?)\n","\n","É um método usado para normalizar o alcance de variaveis ou caracteristicas independentes dos nossos dados. Em processamento de dados isso também é conhecido como normalização de dados e geralmente é feito durante a etapa de processamento dos dados.\n"]},{"cell_type":"markdown","metadata":{"id":"Wr5_2hRStRgJ"},"source":["##Escalas de proporção(Ratio Scales):\n","\n","\n","*   As unidades são igualmente espaçadas\n","*   As operações matemáticas fundamentais são válidas (+-/*)\n","*   Ex: Peso, Altura.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xfZfRGOluEKI"},"source":["## Escala de intervalo\n","\n","*  As unidades são igualmente espaçadas, mas não existe um zero real (Portanto as operações '*/' não são válidas).\n","\n","* ex: Temperatura, direção de uma bussola.\n","\n","Isso pois o valor Zero tem um significado. No caso da temperatura, o 0 não significa ausencia de calor. Na bussola, 0º não é uma ausencia de direção, mas uma direção em sí."]},{"cell_type":"markdown","metadata":{"id":"Kdwlf7HBuD9w"},"source":["##Escala Ordinária\n","\n","*  A ordem das unidades são importantes. Mas não são igualmente espaçadas.\n","\n","*  Um exemplo é o método avaliativo americano, como A+, A."]},{"cell_type":"markdown","metadata":{"id":"ieCkwAG1uDxi"},"source":["##Escala Nominal\n","\n","*  Os dados são categoricos, mas as categorias não tem relação uma com a outra\n","\n","*  Um exemplo seria times de um esporte."]},{"cell_type":"markdown","metadata":{"id":"xWtuaaTB110g"},"source":["Dado a importância dos tipos de dados para Machine Learning, pandas, tem um número interessante de funções para lidar e converter entre escalas de medidas. Vamos começar com os dados nominais, que em pandas são chamados de dados **categóricos**.\n","Pandas atualmente tem um tipo embutido para dados categóricos, e podemos escolher uma coluna para simplificar usando o método 'astype'. Astype tenta mudar o dado por baixo o tipo de dado, neste caso, para dados categóricos, e mais adiante muda-lo para dados ordinários."]},{"cell_type":"code","metadata":{"id":"zPxWYjUKqHAe","executionInfo":{"status":"aborted","timestamp":1620944107523,"user_tz":180,"elapsed":3697,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["import pandas as pd\n","#Para exemplificar, vamos criar um um dataframe das letras de notas do sistema avaliativo americano. Vamos criar os indices\n","#E fazer um pouco de julgamento humano de quão bem é o desempenho do aluno.\n","\n","df = pd.DataFrame(['A+','A','A-','B+','B','B-','C+','C','C-','D+','D'],\n","                  index = ['excelente','excelente','excelente','bom','bom','bom','regular','regular','regular','ruim','ruim'],\n","                  columns = ['Notas'])\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sTeeCFD8T0X","executionInfo":{"status":"aborted","timestamp":1620944107524,"user_tz":180,"elapsed":3680,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos checar os tipos dos dados, retornará como obejetos, uma vez que passamos apenas strings para o dataframe\n","df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtAVGKzX-BeM","executionInfo":{"status":"aborted","timestamp":1620944107525,"user_tz":180,"elapsed":3666,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Nós podemos, contudo, dizer ao pandas que queremos mudar o tipo para categóricos, usando a função 'astype()'.\n","df['Notas'].astype('category').head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Y1FC4M6-cus","executionInfo":{"status":"aborted","timestamp":1620944107873,"user_tz":180,"elapsed":4002,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Estamos vendo agora que temos 11 categorias, e o pandas está ciente de quais categorias são. Mais interessante é que nossos\n","#dados não são apenas categóricos. Mas ordenado, isso é, um A+ > A-. Podemos dizer ao pandas como organizar a ordem criando\n","#criando os dados categóricos que é uma lista das ordem categóricas, e então colocando ordenamento como true, veja:\n","\n","categories = pd.CategoricalDtype(categories=['D','D+','C-','C','C+','B-','B','B+','A-','A','A+'],ordered = True)\n","# E passamos ela para a função 'astype()'\n","grades = df['Notas'].astype(categories)\n","grades.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttgFwSFeBR_U","executionInfo":{"status":"aborted","timestamp":1620944107875,"user_tz":180,"elapsed":3989,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vemos que agora o pandas só não está ciente das onze categorias, como também sabe a ordem dessas categorias. Agora,\n","#O que podemos fazer com isso? Como há uma ordem, podemos usar para fazer comparações booleanas. Por exemplo, se quisermos\n","#comparar, as notas a uma nota C, que a comparação lexical não retorna exatamente o que esperavamos.\n","\n","df[df['Notas'] > 'C'] #df não está organizado hierarquicamente, como o dataframe 'grades'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQJIFnaXK6zm","executionInfo":{"status":"aborted","timestamp":1620944107876,"user_tz":180,"elapsed":3976,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#C+ é maior que C, mas D não. Contudo, se transmitirmos pelo dataframe que tem um tipo ordenado de categorias.\n","\n","grades[grades > 'C']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FGEJjfuLqyu","executionInfo":{"status":"aborted","timestamp":1620944107877,"user_tz":180,"elapsed":3974,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vemos que o operador funcionou como esperavamos. Nós podemos usar certos operações matemáticas, como maximo, minimos\n","#em nossos dados ordinários."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDOl6OCgMvdZ","executionInfo":{"status":"aborted","timestamp":1620944107878,"user_tz":180,"elapsed":3972,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#As vezes é útil representar dados categóricos como True ou False conforme aplicados a categorias. ISso é muito comum na extração\n","#de caracteristicas (features), que é um tópico sobre a mineração de dados. Variaveis com valores booleanos são geralmente\n","#chamadas de variaveis ficticias. E pandas tem função embutida chamada 'get_dummies' que converte valores de uma coluna\n","#em multiplas colunas de zeros e um, indicando presença de variaveis ficticias (dummy variable). Raramente usada, mas quando\n","#usada é muito útil."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sOu6tCAOejC","executionInfo":{"status":"aborted","timestamp":1620944107878,"user_tz":180,"elapsed":3960,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Tem mais uma operação baseada em escalas que é interessante dizer. Que é converter algo de escala de proporção, ou de intervalo\n","#Para dados categoricos. Isso parece contra intuitivo pois estamos perdendo informação dos valores. Mas é bem usado, por exemplo.\n","#Se estivermos verificando a frequencia das categorias, isso pode ser uma abordagem bem útil, e histogramas são geralmente\n","#feitos de valores com intervalo, ou proporção. E mais, se estivermos trabalhando com aprendizado de maquina (Machine learning)\n","#para classificar, é preciso estar usando dados categóricos, então reduzir a dminesão é util para aplicar determinada técnica.\n","\n","#Pandas tem uma função chamada 'cut()' que leva como argumento alguma estrutura de array (Uma coluna de um dataframe, Séries),\n","#Isso também leva um número de armazenamento a ser usado, e todos esses armazenamentos são mantidos em espaços iguais.\n","\n","#Vamos novamente usar os dados do census para o exemplo. Nós vimos que agrupar por estados, então agregar para obter uma lista\n","#da média das contagens por estado. Se posteriormente, aplicarmos 'cut' para fazer isso, digamos, uns 10 armazenamentos (bins)\n","#podemos ver os estados listados como categóricos usando a média das contagens do estado\n","\n","import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv('census.csv')\n","\n","#agora que trouxemos o dataset, vamos reduzir aos dados do país.\n","df = df[df['SUMLEV'] == 50]\n","#E agora para agrupar.\n","df=df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n","\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w267CKAZTjb9","executionInfo":{"status":"aborted","timestamp":1620944107879,"user_tz":180,"elapsed":3948,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#agora queremos criar 'bins' em cada. podemos usar 'cut()', então:\n","pd.cut(df,10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jU6ljl0VgGI","executionInfo":{"status":"aborted","timestamp":1620944107880,"user_tz":180,"elapsed":3947,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Aqui podemos observar que os estados do Alaska e Alabama caem na mesma categoria, enquanto california e Columbia caem em \n","#categorias diferentes\n","\n","#'Cutting' é apenas uma maneira de criar categorias em nossos dados, e existem outros métodos. POr exemplo.\n","#'CUt()' nos fornece intervalos de dados, aonde o espaço em cada categoria é do mesmo tamanho. Mas as vezes queremos\n","#formar categorias baseado na frequencia, queremos que o número de itens em cada 'bin' seja o mesmo, ao invés do espaço entre\n","#elas. Isso depende do formato dos seus dados e o que você pretende fazer com ele."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6aNB19yh__US"},"source":["# Mesa pivô (Pivot table)\n","\n","Uma mesa pivô é uma maneira de sintetizar os dados de um DataFrame para um próposito particular. Isso faz um pesado uso da função 'agg()'. Uma mesa pivô é por si mesma um DataFrame,   aonde as linhas representam um variavel de interesse, e as colunas outra, e as celulas outros valores agregados. Uma mesa pivô também tende a incluir valores marginais, que são as somas de cada coluna e linha. Isso nos permite ver a relação entre duas variaveis com mais clareza."]},{"cell_type":"code","metadata":{"id":"s44KWKHHCHrF","executionInfo":{"status":"aborted","timestamp":1620944107880,"user_tz":180,"elapsed":3944,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vamos fazer uma mesa pivô nos pandas\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-7IzfezCY0P","executionInfo":{"status":"aborted","timestamp":1620944107881,"user_tz":180,"elapsed":3931,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["# Aqui vamos usar os dados chamado 'Times Higher Education World University Ranking dataset', que é um dos mais influentes\n","#rankings das universidades. Vamos importa-lo\n","\n","df = pd.read_csv('cwurData.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Vx21FCaUL19","executionInfo":{"status":"aborted","timestamp":1620944107881,"user_tz":180,"elapsed":3918,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Aqui podemos ver cada instituição, seu rank nacional, qualidade de educação, outras métricas, e sua nota geral.\n","#Vamos dizer que queremos criar uma nova coluna chamada 'Nivel do rank', aonde instituições em posição de '1-100', aonde\n","#são caracterizados como 'Tier 1', de '101 - 200' como 'tier 2' e por ai adiante. \n","\n","#Agora já sabemos como fazer isso, então vamos:\n","def create_category(ranking):\n","  #Desde que o rank é apenas um inteiro. \n","  if (ranking >= 1) & (ranking < 100):\n","    return ('Tier 1')\n","  elif (ranking >= 101) & (ranking <= 200):\n","    return ('Tier 2')\n","  elif (ranking >= 201) & (ranking <= 300):\n","    return ('Tier 3')\n","  return ('Low Tier (Bronze)')\n","\n","#Agora podemos aplicar essa função essa coluna de dados para criar uma nova série.\n","df['rank_level'] = df['world_rank'].apply(lambda x: create_category(x))\n","df['rank_level'].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxJvex_rZ7w5","executionInfo":{"status":"aborted","timestamp":1620944107882,"user_tz":180,"elapsed":3906,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["# A mesa de pivô nos permite colocar como eixo uma dessas colunas, e comparar com outra coluna com os indices das linhas.\n","#Vamos dizer que queremos comparar o level do rank versus o país das universidades e nós queremos comparar os termos da \n","#qualificação total.\n","\n","#Para fazer isso, vamos dizer ao pandas que queremos os valores da qualificação,e o indice para ser os países e as colunas\n","#para ser rank levels. Então nós especificamos isso a função de agregação, e aqui nós iremos usar a média do numpy para ter as\n","#qualificação média das universidades nesse país.\n","df.pivot_table(values = 'score', index = 'country', columns = 'rank_level', aggfunc = [np.mean]).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WZsmW5khPEi","executionInfo":{"status":"aborted","timestamp":1620944107883,"user_tz":180,"elapsed":3893,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Aqui vemos que há uma organização hierarquica no dataframe onde o indice, ou linhas, são por países e as colunas possuem\n","#dois level. Perceba também que temos alguns valores NaNs, por exemplo, a argentina indica que apenas tem universidades de \n","#tier mais baixo.\n","\n","#As meses de pivo não são limitadas a uma única função, que você pode querer aplicar, podemos passar um parametro chamado\n","#'aggfunc()', que é uma lista de diferentes funções a se aplicar. E o pandas irá te fornecer o resultado usando nomes de \n","#colunas hierarquicamente\n","\n","df.pivot_table(values = 'score', index = 'country', columns = 'rank_level', aggfunc=[np.mean, np.max]).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBf_DNf7tNI4","executionInfo":{"status":"aborted","timestamp":1620944107884,"user_tz":180,"elapsed":3880,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Então agora vemos que temos os dois, a média e o max. Como mencionado anteriormente, também podemos sintetizar os valores\n","# dentro de uma coluna de alto nivel. Por exemplo, queremos ver uma média geral do país para a média e queremos ver o máximo do\n","# máximo, podemos indicar ao pandas que queremos nos forneça valores marginais \n","df.pivot_table(values='score', index  = 'country', columns = 'rank_level', aggfunc=[np.mean, np.max],\n","               margins = True).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDDq7GcP7Usz","executionInfo":{"status":"aborted","timestamp":1620944107885,"user_tz":180,"elapsed":3867,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Uma mesa pivot é apenas um dataframe multinivel, e podemos acessar séries, ou celulas no dataframe de maneira similar\n","#que fazemos com dataframes comuns\n","\n","#Vamos criar um novo dataframe do nosso exemplo anterior\n","new_df = df.pivot_table(values = 'score', index='country', columns = 'rank_level',aggfunc=[np.mean, np.max],\n","                        margins = True)\n","\n","print(new_df.index)\n","print(new_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGloYhsr8ZYb","executionInfo":{"status":"aborted","timestamp":1620944107886,"user_tz":180,"elapsed":3856,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Podemos ver que as colunas são hierarquicas. Os indices das colunas de alto nivel possuem duas categorias: Média e max\n","#e as colunas de baixo nivel possuem quatro categorias, que são os ranks que definimos inicialmente. Como eu questiono o dataframe\n","#Se quisermos obter a média das notas das universidades de tier 1 em cada país? Apenas precisamos fazer duas projeções \n","#de dataframes, o primeiro para média e o segundo para o Tier 1 das universidades.\n","\n","new_df['mean']['Tier 1'].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1c35BhMAaPo","executionInfo":{"status":"aborted","timestamp":1620944107887,"user_tz":180,"elapsed":3843,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Podemos ver que a saída é um objeto do tipo série, que pode ser confirmado por imprimir o tipo. Apenas lembrando que quando\n","#projetamos uma coluna pra fora do dataframe, nos é retornado uma série.\n","\n","type(new_df['mean']['Tier 1'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIWIqjmwBaAo","executionInfo":{"status":"aborted","timestamp":1620944107888,"user_tz":180,"elapsed":3826,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#E se quisermos encontrar o país que possui a maior média das avaliações de universidades tier 1? Podemos usar idxmax() função\n","new_df['mean']['Tier 1'].idxmax()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQrI7vB3CQ_-","executionInfo":{"status":"aborted","timestamp":1620944107889,"user_tz":180,"elapsed":3823,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#A função idxmax() não é especial para mesas pivos, mas sim uma função embutida nos objetos do tipo Séries.\n","#Como não temos tempo para ir atraves de todas as funções e metodos existentes em pandas e numpy, encorajo você \n","#para a explorar o API das bibliotecas e aprender mais independentemente."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"opEGkzC5CxwW","executionInfo":{"status":"aborted","timestamp":1620944107890,"user_tz":180,"elapsed":3809,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Se quisermos atingir um diferente formato para nossa mesa pivo, podemos usar as funções 'stack' e 'unstack'.\n","#'Stacking' é girar a coluna mais baixa para a superior, e 'Unstacking' é exatamente a operação contrária\n","\n","#Antes de ir para um exemplo, vamos relembrar nosso dataframe\n","new_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTDtUXs_D3bP","executionInfo":{"status":"aborted","timestamp":1620944107891,"user_tz":180,"elapsed":3796,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#agora vamos tentar usar a função stack e transformar as colunas inferiores para as linhas superiores\n","new_df = new_df.stack()\n","new_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_4uc_GUFQg4","executionInfo":{"status":"aborted","timestamp":1620944107892,"user_tz":180,"elapsed":3783,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Bem agora vamos fazer um 'unstack' para ver o que sai\n","new_df = new_df.unstack()\n","new_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgrJb5fxGAlA","executionInfo":{"status":"aborted","timestamp":1620944107893,"user_tz":180,"elapsed":3769,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Vimos que ele retornou ao dataframe original, então podemos nos perguntar, o que acontece se fizermos 'unstack' duas vezes\n","#seguidas? \n","new_df.unstack().unstack().head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTjSt5JyRFLj"},"source":["# Funcionalidades de Data/Horário"]},{"cell_type":"markdown","metadata":{"id":"ULTGVfcvSOvO"},"source":["Agora vamos dar uma olhada nas funcionalidades de Data e horário do pandas. O pandas torna a manipulação bem flexivel e nos permite conduzir analises como analises de séries de tempos."]},{"cell_type":"code","metadata":{"id":"mBW69PD8RNl_","executionInfo":{"status":"aborted","timestamp":1620944107894,"user_tz":180,"elapsed":3766,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Z4BByfSSvtH"},"source":["## Timestamp (Carimbo)"]},{"cell_type":"code","metadata":{"id":"3FmL-IwOSumt","executionInfo":{"status":"aborted","timestamp":1620944107895,"user_tz":180,"elapsed":3755,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Pandas possui classes principais relacionadas ao tempo, 'Timestamp', 'DatetimeIndex', 'Period', 'PeriodIndex'. Primeiro,\n","#Vamos olhar para o timestamp. Isso representa um simples carimbo e associa os valores com pontos no tempo.\n","\n","#Por exemplo, vamos criar uma string da data e horario de hoje, e isso será nosso timestamp, timestamp é intercalável com\n","#as funções de data/hora do python\n","\n","pd.Timestamp('11/3/2021  9:46AM')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3qrUPf4Ssp1","executionInfo":{"status":"aborted","timestamp":1620944107895,"user_tz":180,"elapsed":3743,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Também podemos criar um timestamp passando multiplos parametros, como ano, mês, dia, hora, minuto, separadamente\n","pd.Timestamp(2021, 11, 3, 9, 49)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1L070JQ1VYSB","executionInfo":{"status":"aborted","timestamp":1620944107896,"user_tz":180,"elapsed":3732,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Timestamp também alguns atributos bem uteis, como isoweekday(), que retornará o dia da semana\n","#Aonde 1 representa Segunda-feira, e 7 representa domingo\n","\n","pd.Timestamp(2021,3,11,9,56).isoweekday()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0eQhSR3XLc7","executionInfo":{"status":"aborted","timestamp":1620944107909,"user_tz":180,"elapsed":3733,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Também podemos extrair o dia, mês, ano etc, de um timestamp\n","pd.Timestamp(2021, 3, 11, 9, 58).month"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nhb13J3FXpYM"},"source":["##Periodo"]},{"cell_type":"code","metadata":{"id":"Pc093-7BXmyG","executionInfo":{"status":"aborted","timestamp":1620944107910,"user_tz":180,"elapsed":3720,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Supomos que não estamos interessanto em um ponto especifico no tempo, ao invés disso queremos um periodo de tempo. \n","#Isso é onde a classe periodo entra na história. Periodo é um intervalo no tempo, como um dia especifico, ou um mês\n","pd.Period('3/2021')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlgiutnjYrf3","executionInfo":{"status":"aborted","timestamp":1620944107913,"user_tz":180,"elapsed":3711,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Você pode perceber que foi indicado a dimensão do nosso intervalo, que no caso veio na saída um 'M' de 'month  , \n","pd.Period('3/11/2021') #Lembrando que tem que organizar as horas pelo modelo americano"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u27KmQlEZXJd","executionInfo":{"status":"aborted","timestamp":1620944107913,"user_tz":180,"elapsed":3699,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#o periodo é todo o intervalo de tempo que especificarmos, e aritmética do periodo é intuitiva, por exemplo, se quisermos \n","#os proximos 5 meses da data de hoje. \n","pd.Period('3/2021') + 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX9N4-gNaIHr","executionInfo":{"status":"aborted","timestamp":1620944107914,"user_tz":180,"elapsed":3687,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Ou se quisermos dois dias anteriores\n","pd.Period('3/11/2021') -2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LAqhOejujqii"},"source":["##DatetimeIndex and PeriodIndex"]},{"cell_type":"code","metadata":{"id":"_Z_z2pDNaRuN","executionInfo":{"status":"aborted","timestamp":1620944107914,"user_tz":180,"elapsed":3673,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#O indice de um 'timestamp'(Carimbo de tempo) é um 'DatetimeIndex'. Vamos olhar um rápido exemplo. Primeiro, vamos criar\n","# nosso exemplo, vamos criar uma série com os 3 primeiros dias de um mês. Quando olharmos para a série, cada 'Timestamp' é\n","#o indice e tem um valor associada a ele, nesse caso, a,b,c.\n","\n","t1 = pd.Series(list('abc'), [pd.Timestamp('2021/9/1'), pd.Timestamp('2021/9/2'),\n","                             pd.Timestamp('2021/9/3')])\n","t1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6A1bDzR4lYQh","executionInfo":{"status":"aborted","timestamp":1620944107915,"user_tz":180,"elapsed":3662,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vamos checar  o tipo do indice da nossa série\n","type(t1.index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BDgJ0Evsm583","executionInfo":{"status":"aborted","timestamp":1620944107915,"user_tz":180,"elapsed":3650,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Similarmente podemos criar um indice baseado no periodo\n","t2 = pd.Series(list('def'), [pd.Period('2021-09'), pd.Period('2021-10'), pd.Period('2021-11')])\n","t2  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-H4jhNhnhTG","executionInfo":{"status":"aborted","timestamp":1620944107916,"user_tz":180,"elapsed":3639,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#De forma similar, podemos checar o tipo do indice\n","type(t2.index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-MhBjr7nr8I"},"source":["##Convertendo to Data/Horario"]},{"cell_type":"code","metadata":{"id":"ayGMwiIRnpap","executionInfo":{"status":"aborted","timestamp":1620944107916,"user_tz":180,"elapsed":3625,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vamos dar uma olhada em como converter para data/hora. Suponha que temos uma lista de dados em strings e queremos criar\n","#um novo dataframe\n","\n","#Vamos tentar diferentes formatos de data/horas.\n","d1 = [' 2 June 2013','Aug 29, 2014','2015-06-26','7/12/16']\n","#E alguns dados aleatórios\n","ts3 = pd.DataFrame(np.random.randint(10, 100, (4,2)), index = d1,\n","                   columns = list('ab'))\n","ts3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"isNcXhHwpKOc","executionInfo":{"status":"aborted","timestamp":1620944107917,"user_tz":180,"elapsed":3612,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Usando pandas 'to_datetime', pandas irá tentar converter estes para data/hora e coloca-los em formato padrão\n","\n","ts3.index = pd.to_datetime(ts3.index)\n","ts3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJlFZPpPpwWT","executionInfo":{"status":"aborted","timestamp":1620944107918,"user_tz":180,"elapsed":3599,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#A função datetime também tem opções para mudar a ordem da data. Por exemplo, podemos passar o argumento 'dayfirst = True'\n","# para colocar o dia em primeiro e ficar no modelo europeu, e evitar o modelo americano.\n","\n","pd.to_datetime(\"4.7.12\", dayfirst=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdtroqQsqcs_"},"source":["##Timedelta"]},{"cell_type":"code","metadata":{"id":"ARVGa1qpqU2J","executionInfo":{"status":"aborted","timestamp":1620944107919,"user_tz":180,"elapsed":3589,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["# Timedeltas são diferenças de tempo, Isso não é o mesmo que periodo, mas conceitualmente similar. Por exemplo, se nós quisermos\n","# a difença entre 3/9 e 1/9, teremos um timeDelta(Intervalo de tempo) de 2 dias.\n","\n","pd.Timestamp('9/3/2021') - pd.Timestamp('9/1/2021')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEqs1GoPr2nn","executionInfo":{"status":"aborted","timestamp":1620944107919,"user_tz":180,"elapsed":3577,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Nós também podemos fazer algo como encontrar que data e hora é 12dias e 3horas no passado de 2/9 as 8:10Am\n","pd.Timestamp('9/2/2021 8:10AM') + pd.Timedelta('12D 3h')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GHxwDXvsq_p"},"source":["##Offset"]},{"cell_type":"code","metadata":{"id":"ltPKiCLSsmgS","executionInfo":{"status":"aborted","timestamp":1620944107920,"user_tz":180,"elapsed":3566,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Offset é semelhante ao timedelta, mas isso segue algumas regras do calendário. Offset permite flexibilidade em termos\n","#dos tipos de intervalos. além da hora, dia, semana, mês, etc. Isso também tem dia de negócios, fim de mês, quase inicio de mês\n","\n","#Vamos criar um timestamp pra ver como é isso\n","pd.Timestamp('3/11/2021').weekday()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUxcVL4vt0ym","executionInfo":{"status":"aborted","timestamp":1620944107921,"user_tz":180,"elapsed":3553,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora podemos adicionar o timestamp com a semana a frente\n","pd.Timestamp('3/11/2021') +pd.offsets.Week() #Retornou o valor de uma semana a frente"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWLuJIZxvGb9","executionInfo":{"status":"aborted","timestamp":1620944107922,"user_tz":180,"elapsed":3542,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vamos tentar fazer isso com o fim do mês. então podemos ter o ultimo dia de março\n","pd.Timestamp('3/11/2021') + pd.offsets.MonthEnd() #Retornou o ultimo dia do mês"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BfAKHfZMv2F2"},"source":["##Trabalhando com dados em um dataframe"]},{"cell_type":"code","metadata":{"id":"mu9bqq3Mvt1W","executionInfo":{"status":"aborted","timestamp":1620944107922,"user_tz":180,"elapsed":3530,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora, vamos dar olhada em alguns truques ao se trabalhar com datas em um dataframe. Suponha que nós queremos olhar nove medidas\n","#coletadas quinzenalmente, todo domingo, iniciando em Outubro de 2016. Usando 'data_range', nós podemos criar esse DatetimeIndex\n","#em 'data_range' nós temos que especificar a data de inicio, ou a final, se não especificado, por padrão será a de inicio\n","#Então nós temos que especificar o número de periodos, e a frequencia. Aqui, nós colocaremos '2W-SUN', Que significa quinzenalmente\n","#(Duas semanas) iniciando no domingo\n","\n","dates = pd.date_range('10-1-2016', periods = 9, freq = '2W-SUN')\n","dates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXDQV5kmydvW","executionInfo":{"status":"aborted","timestamp":1620944107923,"user_tz":180,"elapsed":3519,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Existem muitas frequencias que podemos especificar, por exemplo, dia de trabalho (Business day)\n","pd.date_range('04-1-2016',periods = 12, freq = 'B')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qIVRGHRPzTuz","executionInfo":{"status":"aborted","timestamp":1620944107923,"user_tz":180,"elapsed":3507,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["# Ou podemos fazer trimestralmente(Quartely), com o trimestre inicando em Junho\n","pd.date_range('04-01-2016', periods= 12, freq = 'QS-JUN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFL5IEmjzvcG","executionInfo":{"status":"aborted","timestamp":1620944107924,"user_tz":180,"elapsed":3496,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vamos voltar ao nosso exemplo de semanalmente inicando no domingo, e criar um dataframe usando esses dados e alguns dados\n","#aleatórios\n","dates = pd.date_range('10-01-2016', periods=9, freq='2W-SUN')\n","df = pd.DataFrame({'count 1' : 100 + np.random.randint(-5, 10, 9).cumsum(),\n","                   'Count 2' : 120 + np.random.randint(-5, 10, 9)}, index = dates)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eWo02Ax0-HG","executionInfo":{"status":"aborted","timestamp":1620944107924,"user_tz":180,"elapsed":3482,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Primeiro, podemos checar que dia da semana a data especifica é (NO caso aqui, esperamos que seja todos domingos), Vamos ver se\n","#bate com a frenquencia que defininimos\n","df.index.weekday_name #Não sei o porque, mas isso não está funcionando"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-DafAMc136u","executionInfo":{"status":"aborted","timestamp":1620944107925,"user_tz":180,"elapsed":3469,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Podemos também usar diff() para encontrar a diferença entre o valor de cada data;\n","df.diff()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIb-E88j3JBG","executionInfo":{"status":"aborted","timestamp":1620944107926,"user_tz":180,"elapsed":3456,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Suponha que queremos saber a média da contagem de cada mês, podemos fazer isso usando 'resample'. Converter de uma alta\n","#Para uma baixa frenquencia é chamado de 'downsampling' (Vamos falar disso em um momento)\n","df.resample('M').mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxrpu5qw4KNA","executionInfo":{"status":"aborted","timestamp":1620944107927,"user_tz":180,"elapsed":3441,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Agora vamos falar sobre datetime indexação e slicing, que é um maravilhoso recurso do pandas.\n","#Por exemplo, nós podemos usara indexação de uma string parcial para encontrar valores de um ano particular.\n","df['2017'] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIhQR0HZ4tc8","executionInfo":{"status":"aborted","timestamp":1620944107928,"user_tz":180,"elapsed":3428,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Ou podemos fazer isso para um mês especifico\n","df['2016-12']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZeaf1Ic412G","executionInfo":{"status":"aborted","timestamp":1620944107929,"user_tz":180,"elapsed":3415,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Ou podemos mesmo fazer um slice do alcance dos dados. Por exemplo, aqui nós apenas queremos os valores de dezembro de 2016\n","#A frente.\n","\n","df['2016-12' :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MLKY3ax5dY4","executionInfo":{"status":"aborted","timestamp":1620944107930,"user_tz":180,"elapsed":3412,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":["#Nós iremos falar de resampling em outra aula. E isso talvez seja amis claro de com usar isso. De novo, se tiver que lidar\n","#um montante de dados de data/hora, essa aula se tornará importante para voltar, revisar e entender. E também a funcionalidade\n","#do pandas em respeito a data/hora é bem fenomenal e a documentação descreve isso em mais detalhes\n","# Isso pode ser encontrado no link a seguir:\n","#https://pandas.pydata.org/docs/user_guide/timeseries.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5w4S9I16fE_","executionInfo":{"status":"aborted","timestamp":1620944107931,"user_tz":180,"elapsed":3410,"user":{"displayName":"Raphael Cardoso de Almeida","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1JjBW1_LcFlrn9f-p1JT7cE6WtaGqaIOqYEThTg=s64","userId":"08216405031429412072"}}},"source":[""],"execution_count":null,"outputs":[]}]}